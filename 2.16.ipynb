{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1e89f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Linear(in_features=261, out_features=196, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# MNIST save model p4 (Sequential)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "from PIL import Image\n",
    "import torchvision.transforms.v2 as tfs\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# GPU setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "class RavelTransform(nn.Module):\n",
    "    def forward(self,item):\n",
    "        return item.ravel()\n",
    "\n",
    "\n",
    "# Options to buld models\n",
    "# option 1\n",
    "model_0 = nn.Sequential(\n",
    "    nn.Linear(28 *28, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32,10)\n",
    ")\n",
    "\n",
    "# option2\n",
    "model_1 = nn.Sequential()\n",
    "model_1.add_module('layer_1', nn.Linear(28 *28, 32))\n",
    "model_1.add_module('relu',nn.ReLU())\n",
    "model_1.add_module('layer_2', nn.Linear(32, 10))\n",
    "\n",
    "\n",
    "# option3\n",
    "class DigitNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_hid, out_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "                    nn.Linear(28 *28, 32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(32,10)\n",
    "                )\n",
    "    def forward(self,x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "model_2 = DigitNN(28 * 28, 128, 10) \n",
    "\n",
    "# option4\n",
    "block = nn.Sequential(\n",
    "    nn.Linear(32, 32),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(32,16),\n",
    "    nn.LeakyReLU()\n",
    "    )\n",
    "model_3 = nn.Sequential()\n",
    "model_3.add_module('layer_1', nn.Linear(28 *28, 32))\n",
    "model_3.add_module('relu',nn.ReLU())\n",
    "model_3.add_module('block', block)\n",
    "model_3.add_module('layer_2', nn.Linear(16, 10))\n",
    "\n",
    "# option5 ModuleList (Нужен для регистрации всех слоев в моделе)\n",
    "class DigitNN2(nn.Module):\n",
    "    def __init__(self, input_dim = 28*28, out_dim = 10, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [ nn.Linear( input_dim // n, input_dim // (n+1)) for n in range(1, n_layers+1) ])\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "                    nn.Linear(196, 32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(32,10)\n",
    "                )\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x).tanh()\n",
    "\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "model_4 = DigitNN2() \n",
    "\n",
    "# option 6 ModuleList+Sequential\n",
    "class DigitNN3(nn.Module):\n",
    "    def __init__(self, input_dim = 28*28, out_dim = 10, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear( input_dim // n, input_dim // (n+1)) for n in range(1, n_layers+1)]\n",
    "        self.net0 = nn.Sequential(*self.layers)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "                    nn.Linear(196, 32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(32,10)\n",
    "                )\n",
    "    def forward(self, x):\n",
    "        for layer in self.net0:\n",
    "            x = layer(x).tanh()\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "model_5 = DigitNN3() \n",
    "model = model_5\n",
    "\n",
    "# option 7 ModuleList with names\n",
    "class DigitNN4(nn.Module):\n",
    "    def __init__(self, input_dim = 28*28, out_dim = 10, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for n in range(1, n_layers+1):\n",
    "            self.layers.add_module(f\"layer_{n}\", nn.Linear(input_dim // n, input_dim // (n+1) ))\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "                    nn.Linear(196, 32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(32,10)\n",
    "                )\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x).tanh()\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "model_6 = DigitNN4() \n",
    "model = model_6\n",
    "\n",
    "model.to(device)\n",
    "print(model.layers.layer_3)\n",
    "\n",
    "# Option 8 ModuleDict\n",
    "class DigitNN5(nn.Module):\n",
    "    def __init__(self, input_dim = 28*28, out_dim = 10, n_layers=3, act_type = None):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.act_type = act_type\n",
    "        for n in range(1, n_layers+1):\n",
    "            self.layers.add_module(f\"layer_{n}\", nn.Linear(input_dim // n, input_dim // (n+1) ))\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "                    nn.Linear(196, 32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(32,10)\n",
    "                )\n",
    "        self.act_lst = nn.ModuleDict({\n",
    "            'relu': nn.ReLU(),\n",
    "            'lk_relu':nn.LeakyReLU()\n",
    "        })\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            # if (Nullcheck) and (key in dict)\n",
    "            if self.act_type and self.act_type in self.act_lst:\n",
    "                x = self.act_lst[self.act_type](x)\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "model_7 = DigitNN5() \n",
    "model = model_7\n",
    "\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "\n",
    "# # Setting trnsform\n",
    "# transforms = tfs.Compose([tfs.ToImage(),\n",
    "#                           tfs.Grayscale(), \n",
    "#                           tfs.ToDtype(torch.float32, scale=True), # converting to float\n",
    "#                           RavelTransform() # or tfs.Lambda(lambda _im: _im.ravel()),\n",
    "#                           ])\n",
    "\n",
    "\n",
    "# dataset_mnist = torchvision.datasets.MNIST(\"datasets\\mnist\", download=True, train=True, transform=transforms)\n",
    "# d_train, d_val = data.random_split(dataset_mnist , [0.7, 0.3])\n",
    "# train_data = data.DataLoader(d_train, batch_size=32, shuffle=True)\n",
    "# train_data_val = data.DataLoader(d_val, batch_size=32, shuffle=False)\n",
    "\n",
    "# optimizer = optim.Adam(params=model.parameters(), lr=0.01)\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# # Lists to store metrics for plotting\n",
    "# train_losses = []\n",
    "# val_losses = []\n",
    "\n",
    "# ep = 3\n",
    "# for _e in range(ep):\n",
    "#     model.train()\n",
    "#     loss_mean = 0\n",
    "#     loss_count = 0\n",
    "    \n",
    "#     train_data_tqdm = tqdm(train_data, leave=True)\n",
    "#     for x_train_img, y_target in train_data_tqdm:\n",
    "#         # Move data to GPU\n",
    "#         x_train_img, y_target = x_train_img.to(device), y_target.to(device)\n",
    "        \n",
    "#         predict = model(x_train_img)\n",
    "#         loss = loss_function(predict, y_target)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         loss_count +=1\n",
    "#         loss_mean = 1/loss_count * loss.item() + (1 - 1/loss_count) * loss_mean\n",
    "#         train_data_tqdm.set_description(f\"Epoch [{_e+1}/{ep}], loss_mean={loss_mean:.3f}\")\n",
    "\n",
    "#     train_losses.append(loss_mean)\n",
    "\n",
    "#     # Validataion\n",
    "#     model.eval()\n",
    "#     Q_val = 0\n",
    "#     count_val = 0\n",
    "\n",
    "#     with torch.no_grad():  # No gradients needed for validation\n",
    "#         for x_val_img , y_target_val in train_data_val:\n",
    "#             # Move data to GPU\n",
    "#             x_val_img, y_target_val = x_val_img.to(device), y_target_val.to(device)\n",
    "            \n",
    "#             p = model(x_val_img)\n",
    "#             loss = loss_function(p,y_target_val)\n",
    "#             Q_val+= loss.item()\n",
    "#             count_val +=1\n",
    "#     Q_val /= count_val\n",
    "#     val_losses.append(Q_val)\n",
    "\n",
    "#     print(f\"loss_mean = {loss_mean:.3f}, Q_val = {Q_val:.3f}\")\n",
    "\n",
    "\n",
    "# # Test\n",
    "# d_test = ImageFolder(\"datasets/MNIST/test\", transform=transforms)\n",
    "# test_data = data.DataLoader(d_test , batch_size=500, shuffle=False)\n",
    "# Q = 0\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "# test_tqdm = tqdm(test_data, leave=True)\n",
    "# with torch.no_grad():  # No gradients needed for testing\n",
    "#     for x_test, y_test in test_tqdm:\n",
    "#         # Move data to GPU\n",
    "#         x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "        \n",
    "#         p = model(x_test) # 500, 10\n",
    "#         p = torch.argmax(p, dim=1) # 500,1\n",
    "#         Q += torch.sum(p == y_test).item()\n",
    "\n",
    "# Q /= len(d_test)\n",
    "# print(f\"Test Accuracy: {Q:.4f}\")\n",
    "\n",
    "\n",
    "# # Plot training and validation losses\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(range(1, ep+1), train_losses, marker='o', label='Training Loss', linewidth=2)\n",
    "# plt.plot(range(1, ep+1), val_losses, marker='s', label='Validation Loss', linewidth=2)\n",
    "# plt.xlabel('Epoch', fontsize=12)\n",
    "# plt.ylabel('Loss', fontsize=12)\n",
    "# plt.title('Training and Validation Loss Over Epochs', fontsize=14)\n",
    "# plt.legend(fontsize=11)\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('training_validation_loss.png', dpi=150)\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"\\nFinal Results:\")\n",
    "# print(f\"Training Loss: {train_losses[-1]:.4f}\")\n",
    "# print(f\"Validation Loss: {val_losses[-1]:.4f}\")\n",
    "# print(f\"Test Accuracy: {Q:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfffc470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "batch_size=8\n",
    "x = torch.rand(batch_size, 5) # тензор x в программе не менять\n",
    "\n",
    "# здесь продолжайте программу\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(5, 16, bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(16),\n",
    "    nn.Linear(16,3)\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "predict = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a15496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# пропишите модель нейронной сети\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 1)\n",
    ") \n",
    "\n",
    "# создание обучающей выборки\n",
    "_x = torch.arange(-5, 5, 0.1)\n",
    "data_y = torch.sin(2 * _x) + 0.2 * torch.cos(10 * _x) + 0.1 * _x ** 2\n",
    "\n",
    "_x.unsqueeze_(-1)\n",
    "data_x = torch.cat([_x, _x ** 2, _x ** 3], dim=1)\n",
    "ds = data.TensorDataset(data_x, data_y)\n",
    "\n",
    "epochs = 20 # число эпох обучения\n",
    "batch_size = 8 # размер батча\n",
    "\n",
    "# создать объект класса DataLoader для датасета ds с размером пакетов batch_size и перемешиванием образов выборки\n",
    "train_data = data.DataLoader(ds,batch_size, shuffle=True)\n",
    "\n",
    "# создать оптимизатор RMSprop для обучения модели с шагом обучения 0.01\n",
    "optimizer = optim.RMSprop(params=model.parameters(), lr=0.01) \n",
    "# создать функцию потерь с помощью класса MSELoss\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "\n",
    "# перевести модель в режим обучения\n",
    "model.train()\n",
    "for _e in range(epochs): # итерации по эпохам\n",
    "    for x_train, y_train in train_data:\n",
    "        predict = model(x_train) # вычислить прогноз модели для данных x_train\n",
    "        loss = loss_func(predict, y_train.unsqueeze(-1)) # вычислить значение функции потерь\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# перевести модель в режим эксплуатации\n",
    "model.eval()\n",
    "# выполнить прогноз модели по всем данным выборки (d_train.data)\n",
    "p = model(data_x)\n",
    "# вычислить потери с помощью loss_func по всем данным выборки; значение Q сохранить в виде вещественного числа\n",
    "Q = loss_func(p , data_y.unsqueeze(-1)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d33dd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=12, out_features=24, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "batch_size=16\n",
    "x = torch.rand(batch_size, 12) # тензор x в программе не менять\n",
    "\n",
    "# здесь продолжайте программу\n",
    "model = nn.Sequential()\n",
    "model.add_module(\"layer1\",nn.Linear(12,24, bias=True) )\n",
    "model.add_module(\"act1\",nn.Tanh() )\n",
    "model.add_module(\"layer2\", nn.Linear(24,10, bias=True) )\n",
    "model.add_module(\"act2\", nn.Tanh() )\n",
    "model.add_module(\"layer3\", nn.Linear(10,1, bias=True) )\n",
    "\n",
    "model.eval()\n",
    "predict = model(x)\n",
    "print(model.layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "248a866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "batch_size=12\n",
    "x = torch.rand(batch_size, 64) # тензор x в программе не менять\n",
    "\n",
    "# здесь продолжайте программу\n",
    "block_bm_dp = nn.Sequential(\n",
    "    nn.Linear(32,32, bias=False),\n",
    "    nn.ELU(),\n",
    "    nn.BatchNorm1d(32),\n",
    "    nn.Dropout(0.3)\n",
    ")\n",
    "\n",
    "model = nn.Sequential()\n",
    "model.add_module(\"input\", nn.Linear(64,32,bias=True))\n",
    "model.add_module(\"act1\", nn.ReLU())\n",
    "for b in range(1,4):\n",
    "    model.add_module(f\"block{b}\",block_bm_dp )\n",
    "model.add_module(\"output\", nn.Linear(32,10, bias=True))\n",
    "\n",
    "model.eval()\n",
    "predict = model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d50615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=12, out_features=32, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# здесь объявляйте класс модели\n",
    "\n",
    "batch_size=12\n",
    "a = torch.rand(batch_size, 7) # тензоры a, b в программе не менять\n",
    "b = torch.rand(batch_size, 12)\n",
    "\n",
    "# здесь продолжайте программу\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.inp_1 = nn.Sequential(\n",
    "            nn.Linear(7,12,bias=True),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.inp_2 = nn.Sequential(\n",
    "            nn.Linear(12,12,bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.out =  nn.Sequential(\n",
    "            nn.Linear(12,32,bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,1,bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, a, b):\n",
    "        a = self.inp_1(a)\n",
    "        b = self.inp_2(b)\n",
    "        c = self.out(a+b)\n",
    "        return c\n",
    "\n",
    "model = MyModel()\n",
    "model.eval()\n",
    "predict = model(a,b)\n",
    "\n",
    "print(model.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04e23b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# здесь объявляйте класс модели\n",
    "\n",
    "batch_size=28\n",
    "x = torch.rand(batch_size, 32) # тензор x в программе не менять\n",
    "\n",
    "# здесь продолжайте программу\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.inp = nn.Sequential(\n",
    "            nn.Linear(32,64,bias=False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "\n",
    "        self.out_1 = nn.Sequential(\n",
    "            nn.Linear(64,10 , bias=True),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        self.out_2 = nn.Sequential(\n",
    "            nn.Linear(64,32 , bias=True),\n",
    "            nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.inp(x)\n",
    "        y = self.out_1(x)\n",
    "        t = self.out_2(x)\n",
    "        return y, t\n",
    "\n",
    "model  = MyModel()\n",
    "model.eval()\n",
    "predict_y, predict_t = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5462e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (layers): ModuleList(\n",
      "    (0-4): 5 x Linear(in_features=16, out_features=16, bias=True)\n",
      "  )\n",
      "  (layer1): Linear(in_features=8, out_features=16, bias=True)\n",
      "  (out): Linear(in_features=16, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 7\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, in_features, out_features, n_hidden_layers, hidden_features):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Linear(hidden_features, hidden_features) for _ in range(n_hidden_layers)]\n",
    "        )\n",
    "        self.layer1 = nn.Linear(in_features, hidden_features)\n",
    "        self.out = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.relu(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            x = torch.relu(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MyModel(8, 2, 5, 16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e11703d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# здесь объявляйте класс модели\n",
    "\n",
    "n = int(input()) # это значение в программе не менять\n",
    "\n",
    "batch_size = 18\n",
    "x = torch.rand(batch_size, 11) # тензор x в программе не менять\n",
    "\n",
    "# здесь продолжайте программу\n",
    "class DeepNetwork(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(11,32, bias=False)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Linear(32, 32) for _ in range(n)]\n",
    "        )\n",
    "        self.output = nn.Linear(32,5, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input(x).relu()\n",
    "        for layer in self.layers:\n",
    "            x = layer(x).relu()\n",
    "        y = self.output(x)\n",
    "        return y\n",
    "        \n",
    "model = DeepNetwork(n)\n",
    "model.eval()\n",
    "\n",
    "predict = model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39217777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# здесь объявляйте класс модели\n",
    "\n",
    "batch_size = 100\n",
    "x = torch.rand(batch_size, 64) # тензор x в программе не менять\n",
    "\n",
    "# здесь продолжайте программу\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(64,32,bias=True)\n",
    "        self.blocks = nn.ModuleDict({\n",
    "            'block_1': nn.Sequential(\n",
    "            nn.Linear(32,32,bias=False),\n",
    "            nn.ELU(),\n",
    "            nn.BatchNorm1d(32)),\n",
    "            'block_2' : nn.Sequential(\n",
    "            nn.Linear(32,32,bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4)) })\n",
    "        self.output = nn.Linear(32,10,bias=True)\n",
    "    def forward(self, x, type_block  = 'block_1'):\n",
    "        x = self.input(x).relu()\n",
    "        x = self.blocks[type_block ](x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel()\n",
    "model.eval()\n",
    "predict = model(x, type_block='block_2' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
