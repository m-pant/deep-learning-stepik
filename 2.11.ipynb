{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea0d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:18<00:00, 103.59it/s]\n",
      "100%|██████████| 1875/1875 [00:18<00:00, 102.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9365\n"
     ]
    }
   ],
   "source": [
    "# MNIST preparation p3 ( working with ImageFolder)\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "from PIL import Image\n",
    "import torchvision.transforms.v2 as tfs\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "\n",
    "class RavelTransform(nn.Module):\n",
    "    def forward(self,item):\n",
    "        return item.ravel()\n",
    "\n",
    "\n",
    "class DigitNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_hid, out_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_dim,num_hid)\n",
    "        self.layer2 = nn.Linear(num_hid, out_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "model = DigitNN(28 * 28, 32, 10)\n",
    "\n",
    "# Setting trnsform\n",
    "transforms = tfs.Compose([tfs.ToImage(),\n",
    "                          tfs.Grayscale(), \n",
    "                          tfs.ToDtype(torch.float32, scale=True), # converting to float\n",
    "                          RavelTransform() # or tfs.Lambda(lambda _im: _im.ravel()),\n",
    "                          ])\n",
    "d_dataset = ImageFolder(\"datasets/MNIST/train\", transform=transforms)\n",
    "train_data = data.DataLoader(d_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "it = iter(train_data)\n",
    "x, y  = next(it)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.01)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "ep = 2\n",
    "model.train()\n",
    "\n",
    "for _e in range(ep):\n",
    "    train_tqdm = tqdm(train_data, leave=True)\n",
    "\n",
    "    for x_train_img, y_target in train_tqdm:\n",
    "        predict = model(x_train_img)\n",
    "        loss = loss_function(predict, y_target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Test\n",
    "d_test = ImageFolder(\"datasets/MNIST/test\", transform=transforms)\n",
    "test_data = data.DataLoader(d_test , batch_size=500, shuffle=False)\n",
    "Q = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for x_test, y_test in test_data:\n",
    "    p = model(x_test) # 500, 10\n",
    "    p = torch.argmax(p, dim=1) # 500,1\n",
    "    Q += torch.sum(p == y_test).item()\n",
    "\n",
    "Q /= len(d_test)\n",
    "print(Q)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c558ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "# import torchvision.transforms as tfs\n",
    "import torchvision.transforms.v2 as tfs\n",
    "\n",
    "img_pil = Image.new(mode=\"RGB\", size=(128, 128), color=(0, 128, 255))\n",
    "transforms = tfs.ToImage()\n",
    "img = transforms(img_pil)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57174029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pantu\\.conda\\envs\\dl\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "\n",
    "from PIL import Image\n",
    "# import torchvision.transforms as tfs\n",
    "import torchvision.transforms.v2 as tfs\n",
    "\n",
    "img_pil = Image.new(mode=\"RGB\", size=(128, 128), color=(0, 128, 255))\n",
    "t = tfs.Compose([tfs.Grayscale(), tfs.ToTensor(), tfs.Normalize([0.5],[1.0])])\n",
    "img = t(img_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56464c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pantu\\.conda\\envs\\dl\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 7\n",
    "from PIL import Image\n",
    "import torchvision.transforms.v2 as tfs\n",
    "\n",
    "img_pil = Image.new(mode=\"RGB\", size=(128, 128), color=(0, 128, 255))\n",
    "\n",
    "# здесь продолжайте программу\n",
    "t= tfs.Compose([tfs.CenterCrop(64), tfs.Resize(128), tfs.ToTensor()])\n",
    "img = t(img_pil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c2bf79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torchvision.transforms as tfs\n",
    "import torchvision.transforms.v2 as tfs\n",
    "\n",
    "# здесь объявляйте класс ToDtypeV1\n",
    "class ToDtypeV1(nn.Module):\n",
    "    def __init__(self, dtype, scale):\n",
    "        super().__init__()\n",
    "        self.dtype = dtype\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.to(self.dtype)\n",
    "        if self.scale and self.dtype in (torch.float16, torch.float32, torch.float64):\n",
    "            x_min = x.min()\n",
    "            x_max = x.max()\n",
    "            x = (x - x_min) / x_max\n",
    "        return x\n",
    "\n",
    "\n",
    "H, W = 128, 128\n",
    "img_orig = torch.randint(0, 256, size=(3, H, W), dtype=torch.uint8) # тензор в программе не менять\n",
    "\n",
    "img_mean = torch.mean(img_orig.float(), [1,2]) # средние для каждого цветового канала (первая ось)\n",
    "img_std = torch.std(img_orig.float().flatten(1,2), dim=1) # стандартное отклонение для каждого цветового канала (первая ось)\n",
    "\n",
    "# здесь продолжайте программу\n",
    "transforms = tfs.Compose([ToDtypeV1(dtype = torch.float32, scale = False), tfs.Normalize(mean=img_mean, std=img_std)])\n",
    "img = transforms(img_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "643c0d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as tfs\n",
    "# import torchvision.transforms.v2 as tfs_v2 - недоступен на Stepik\n",
    "\n",
    "# здесь объявляйте класс AddNoise\n",
    "class AddNoise(nn.Module):\n",
    "    def __init__(self, volume):\n",
    "        super().__init__()\n",
    "        self.volume = volume\n",
    "    def forward(self, x):\n",
    "        noise = torch.randn_like(x) * self.volume\n",
    "        x = x.to(torch.float32) + noise\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "img_pil = Image.new(mode=\"RGB\", size=(128, 128), color=(0, 128, 255))\n",
    "\n",
    "# здесь продолжайте программу\n",
    "tr = tfs.Compose([tfs.ToTensor(), AddNoise(0.1)])\n",
    "img = tr(img_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ebbfd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 \n",
    "import torch\n",
    "\n",
    "t_rnd = torch.randint(-3, 5, (100, ), dtype=torch.float32) # значения этого тензора в программе не менять\n",
    "t_mean = torch.mean(t_rnd)\n",
    "t_max = torch.max(t_rnd[:5])\n",
    "t_min = torch.max(t_rnd[:-3])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
