{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cad601fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:18<00:00, 100.40it/s]\n",
      "100%|██████████| 1875/1875 [00:18<00:00, 101.32it/s]\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MNIST save model p3 ( working with ImageFolder)\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "from PIL import Image\n",
    "import torchvision.transforms.v2 as tfs\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "\n",
    "class RavelTransform(nn.Module):\n",
    "    def forward(self,item):\n",
    "        return item.ravel()\n",
    "\n",
    "\n",
    "class DigitNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_hid, out_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_dim,num_hid)\n",
    "        self.layer2 = nn.Linear(num_hid, out_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "model = DigitNN(28 * 28, 32, 10)\n",
    "\n",
    "\n",
    "# Setting trnsform\n",
    "transforms = tfs.Compose([tfs.ToImage(),\n",
    "                          tfs.Grayscale(), \n",
    "                          tfs.ToDtype(torch.float32, scale=True), # converting to float\n",
    "                          RavelTransform() # or tfs.Lambda(lambda _im: _im.ravel()),\n",
    "                          ])\n",
    "d_dataset = ImageFolder(\"datasets/MNIST/train\", transform=transforms)\n",
    "train_data = data.DataLoader(d_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "it = iter(train_data)\n",
    "x, y  = next(it)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.01)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "ep = 2\n",
    "model.train()\n",
    "\n",
    "for _e in range(ep):\n",
    "    train_tqdm = tqdm(train_data, leave=True)\n",
    "\n",
    "    for x_train_img, y_target in train_tqdm:\n",
    "        predict = model(x_train_img)\n",
    "        loss = loss_function(predict, y_target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "st = model.state_dict() # Веса и смещения для слоя\n",
    "torch.save(st,\"models/mnist_model.tar\" )\n",
    "\n",
    "# Test\n",
    "d_test = ImageFolder(\"datasets/MNIST/test\", transform=transforms)\n",
    "test_data = data.DataLoader(d_test , batch_size=500, shuffle=False)\n",
    "Q = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_tqdm = tqdm(test_data, leave=True)\n",
    "for x_test, y_test in test_tqdm:    \n",
    "    p = model(x_test) # 500, 10\n",
    "    p = torch.argmax(p, dim=1) # 500,1\n",
    "    Q += torch.sum(p == y_test).item()\n",
    "\n",
    "Q /= len(d_test)\n",
    "print(Q)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57248896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "d_test = ImageFolder(\"datasets/MNIST/test\", transform=transforms)\n",
    "test_data = data.DataLoader(d_test , batch_size=500, shuffle=False)\n",
    "Q = 0\n",
    "\n",
    "st_dict = torch.load(\"models/mnist_model.tar\", weights_only=True)\n",
    "model.load_state_dict(st_dict)\n",
    "model.eval()\n",
    "\n",
    "test_tqdm = tqdm(test_data, leave=True)\n",
    "for x_test, y_test in test_tqdm:    \n",
    "    p = model(x_test) # 500, 10\n",
    "    p = torch.argmax(p, dim=1) # 500,1\n",
    "    Q += torch.sum(p == y_test).item()\n",
    "\n",
    "Q /= len(d_test)\n",
    "print(Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be2884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "# эти тензоры в программе не менять\n",
    "layer1 = torch.rand(64, 32)\n",
    "bias1 = torch.rand(32)\n",
    "layer2 = torch.rand(32, 10)\n",
    "bias2 = torch.rand(10)\n",
    "\n",
    "# здесь продолжайте программу\n",
    "data_w = OrderedDict()\n",
    "data_w[\"layer1\"] = layer1\n",
    "data_w[\"bias1\"] = bias1\n",
    "data_w[\"layer2\"] = layer2\n",
    "data_w[\"bias2\"] = bias2\n",
    "\n",
    "torch.save(data_w, 'data_w.tar')\n",
    "\n",
    "data_w2 = torch.load('data_w.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95542da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# здесь продолжайте программу\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(13,32)\n",
    "        self.layer2 = nn.Linear(32,16)\n",
    "        self.layer3 = nn.Linear(16,3)\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x).relu()\n",
    "        x = self.layer2(x).relu()\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel()\n",
    "st = model.state_dict()\n",
    "torch.save(st, 'func_nn.tar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32cb091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# здесь объявляйте класс модели\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(48,32, bias=False)\n",
    "        self.layer2 = nn.Linear(32,16)\n",
    "        self.out = nn.Linear(16,10)\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x).relu()\n",
    "        x = self.layer2(x).relu()\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "x = torch.ones(48) # тензор в программе не менять\n",
    "\n",
    "# здесь продолжайте программу\n",
    "model = MyModel()\n",
    "st_dict = torch.load('toy_nn.tar', weights_only=True)\n",
    "model.load_state_dict(st_dict)\n",
    "model.eval()\n",
    "predict = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eccae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# здесь продолжайте программу\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(25, 16, bias=False)\n",
    "        self.layer2 = nn.Linear(16, 8)\n",
    "        self.out = nn.Linear(8, 5, bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x).tanh()\n",
    "        x = self.layer2(x).tanh()\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "model = MyModel()    \n",
    "opt = optim.Adam(params=model.parameters(), lr=0.02)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "data_state_dict = {\n",
    "    'loss': loss_func.state_dict(),\n",
    "    'opt': opt.state_dict(),\n",
    "    'model': model.state_dict()\n",
    "}\n",
    "torch.save(data_state_dict, 'my_data_state.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b864f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# здесь продолжайте программу\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(10, 8)\n",
    "        self.layer2 = nn.Linear(8, 4)\n",
    "        self.out = nn.Linear(4, 6)\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x).sigmoid()\n",
    "        x = self.layer2(x).sigmoid()\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "model = MyModel()\n",
    "opt = optim.RMSprop(params=model.parameters(), lr = 0.05)\n",
    "st = torch.load('nn_data_state.tar', weights_only=True)\n",
    "\n",
    "model.load_state_dict(st[\"model\"])\n",
    "opt.load_state_dict(st[\"opt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f6f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 \n",
    "import torch\n",
    "\n",
    "# w\n",
    "x1, y1 = 0, 3\n",
    "x2, y2 = -2, 0\n",
    "\n",
    "delta_x = x2 - x1\n",
    "delta_y = y2 - y1\n",
    "\n",
    "# Ax + By + C = 0\n",
    "A = delta_y\n",
    "B = -delta_x\n",
    "C = delta_x * y1 - delta_y * x1\n",
    "\n",
    "w = torch.tensor([C, A, B],dtype=torch.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
