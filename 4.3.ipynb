{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37bfdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "мой дядя самых честныхме позитивной стать стать со ча прести н\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import re\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# GPU setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class TextRNN(nn.Module):\n",
    "    def __init__(self,in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 64\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        self.rnn = nn.RNN(in_features,self.hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(self.hidden_size,out_features )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x,h = self.rnn(x)\n",
    "        y = self.out(h)\n",
    "        return y\n",
    "    \n",
    "class CharsDataset(data.Dataset):\n",
    "    def __init__(self, path, prev_chars=3):\n",
    "        self.prev_chars = prev_chars\n",
    "\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            self.text = f.read()\n",
    "            self.text = self.text.replace('\\ufeff', '')  # убираем первый невидимый символ\n",
    "            self.text = re.sub(r'[^А-яA-z0-9.,?;: ]', '', self.text)  # заменяем все неразрешенные символы на пустые символы\n",
    "\n",
    "        self.text = self.text.lower()\n",
    "        self.alphabet = set(self.text)\n",
    "        self.int_to_alpha = dict(enumerate(sorted(self.alphabet)))\n",
    "        self.alpha_to_int = {b: a for a, b in self.int_to_alpha.items()}\n",
    "        self.alphabet = {'а': 0, 'б': 1, 'в': 2, 'г': 3, 'д': 4, 'е': 5, 'ё': 6, 'ж': 7, 'з': 8, 'и': 9,\n",
    "                         'й': 10, 'к': 11, 'л': 12, 'м': 13, 'н': 14, 'о': 15, 'п': 16, 'р': 17, 'с': 18,\n",
    "                         'т': 19, 'у': 20, 'ф': 21, 'х': 22, 'ц': 23, 'ч': 24, 'ш': 25, 'щ': 26, 'ъ': 27,\n",
    "                         'ы': 28, 'ь': 29, 'э': 30, 'ю': 31, 'я': 32, ' ': 33, '.': 34, '!': 35, '?': 36}\n",
    "        self.num_characters = len(self.alphabet)\n",
    "        self.onehots = torch.eye(self.num_characters)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        # набор предыдущих символов закодированный с помощью onehot\n",
    "        _data = torch.vstack([self.onehots[self.alpha_to_int[self.text[x]]] for x in range(item, item+self.prev_chars)])\n",
    "        \n",
    "        # Символ котоырый нужно спрогнозировать\n",
    "        ch = self.text[item+self.prev_chars]\n",
    "        t = self.alpha_to_int[ch]\n",
    "        return _data, t\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text) - 1 - self.prev_chars\n",
    "\n",
    "\n",
    "d_train = CharsDataset(\"datasets\\\\dataset_rnn\\\\train_data_true.txt\", prev_chars=10)\n",
    "train_data = data.DataLoader(d_train, batch_size=8, shuffle=False)\n",
    "\n",
    "model = TextRNN(d_train.num_characters , d_train.num_characters)\n",
    "optimizer = optim.Adam(params=model.parameters() , lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# for _e in range(epochs):\n",
    "#     loss_mean = 0\n",
    "#     lm_count = 0\n",
    "#     train_tqdm = tqdm(train_data, leave=True)\n",
    "#     for x_train, y_train in train_tqdm:\n",
    "#         x_train = x_train.to(device)\n",
    "#         y_train = y_train.to(device)\n",
    "#         predict = model(x_train).squeeze(0)\n",
    "#         loss = loss_func(predict, y_train.long()) # передается порядковый нормер пегонозируемого вектора\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         lm_count += 1  # Увеличиваем счетчик, а не присваиваем 1\n",
    "#         loss_mean = 1/lm_count * loss.item() + (1 - 1/lm_count) * loss_mean\n",
    "#         train_tqdm.set_description(f\"Epoch {_e+1}/{epochs}, loss_mean={loss_mean:.4f}\")\n",
    "\n",
    "\n",
    "# st = model.state_dict()\n",
    "# torch.save(st, 'model_rnn1.tar')\n",
    "\n",
    "st = torch.load('model_rnn1.tar')\n",
    "model.load_state_dict(st)\n",
    "\n",
    "model.eval()\n",
    "model.cpu()\n",
    "predict = \"Мой дядя самых\".lower()\n",
    "total = 40\n",
    "\n",
    "for _ in range(total):\n",
    "    _data = torch.vstack([d_train.onehots[d_train.alpha_to_int[predict[-x]]] for x in range(d_train.prev_chars, 0, -1)])\n",
    "    p = model(_data.unsqueeze(0)).squeeze(0)\n",
    "    indx = torch.argmax(p, dim=1)\n",
    "    predict += d_train.int_to_alpha[indx.item()]\n",
    "\n",
    "print(predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3608757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
